<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ICCV23 AROW Workshop</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">

  </head>

  <body>

    <div class="container">
    <header class="d-flex flex-wrap justify-content-center py-3 mb-4 border-bottom">
      <a href="" class="d-flex align-items-center mb-3 mb-md-0 me-md-auto link-body-emphasis text-decoration-none">

<!--
        <svg class="bi me-2" width="40" height="32"><use xlink:href="#bootstrap"/></svg>
-->
        <img src=https://iccv2023.thecvf.com/img/LogoICCV23V04.svg" width='100'><rect width="100%" height="100%"></rect></img>
        <span> </span>
        <span class="fs-4"><b>ICCV 2023 Workshop</b> on <span style="color:#33b5ff">A</span>dversarial
        <span style="color:#33b5ff">RO</span>bustness in the Real
        <span style="color:#33b5ff">W</span>orld (<span style="color:#33b5ff">AROW</span>)
      </a>

      <ul class="nav nav-pills">
        <li class="nav-item"><a href="https://cmt3.research.microsoft.com/ICCVworkshopAROW2023/Submission/Index" class="nav-link active" aria-current="page">Submit</a></li>
        <li class="nav-item"><a href="#speakers" class="nav-link">Speakers</a></li>
      </ul>
    </header>
  </div>

<!--
<div class="alert alert-danger text-center" role="alert">
<h1 style="color:red">This website is still work-in-progress. Everything on this page is not final.</h1>
</div>
-->

<br>

<div class="container text-center">
<h2>Welcome to the 4th Workshop on Adversarial Robustness In the Real World (AROW)</h2>
<h2>ICCV 2023, Paris</h2>
<p class="lead">
Recent deep-learning-based methods achieve great performance on various vision applications.
However, insufficient robustness on adversarial cases limits real-world applications of deep-learning-
based methods. AROW workshop aims to explore adversarial examples, as well as, evaluate and
improve the adversarial robustness of computer vision systems.
</p>

</div>

<div class="container">
<ul>
<li><p class="lead"><b>Workshop paper submission deadline</b>: July <del>17</del> 20, 2023 23:59 Pacific Time <a href="#authorguide">[Author Guide]</a> <span class="badge text-bg-primary">NEW</span></p></li> 

<li><p class="lead"><b>Notification to authors</b>: TBD (before August 07, 2023)</p></li>

<li><p class="lead"><b>Camera-ready deadline</b>: TBD (before August 21, 2023)</p></li>

<li><p class="lead"><b>Workshop Date</b>: Oct 2, 2023 (Full-day)</p></li>

<li><p class="lead"><b>Paper Submission Link</b>: <a href="https://cmt3.research.microsoft.com/ICCVworkshopAROW2023/Submission/Index">CMT3 Author Console</a> <span class="badge text-bg-primary">NEW</span></p></li> 
</ul>
</div>






<br>
<hr>
<br>
<div class="text-center" id="news">
<h1>News & Updates</h1>
</div>
<br>

<div class="container lead">
<ul>
<li>2023-07-18 (UTC-7): Good news! We have extended the paper submission deadline by 3 days!</li>
<li>2023-07-05 (UTC-7): We also accept extended abstracts besides long papers. See the updated author guide for detail.</li>
<li>2023-06-30 (UTC-7): The paper submission link is <a href="https://cmt3.research.microsoft.com/ICCVworkshopAROW2023/Submission/Index">here</a>.</li>
<li>2023-06-29 (UTC-7): The paper submission deadline is updated as <u>July 17, 2023</u>.</li>
</ul>
</div><!--container-->








<br>
<hr>
<br>
<div class="text-center" id="overview">
<h1>Overview</h1>
</div>
<br>

<div class="container">
<p class="lead">

Computer vision systems achieve advanced performance, however, research in
adversarial machine learning shows concurrent vision systems are less robust in
comparison to human vision systems.  Perturbation-based adversarial examples
achieve a significant impact on vision systems accuracy but remain a gap toward
real-world scenarios. While recent works demonstrate deep-learning-based
methods are also vulnerable to those more real-world adversarial examples, e.g.,
partial occlusions, atmospheric changes, and style changes.  Such vulnerability
potentially limits the real-world usage of computer vision systems.
Discovering, evaluating, and defending those real-world adversarial examples
helps to understand and improve the robustness of computer vision systems,
which can help the deployment of computer vision systems in safety-critical
applications.  This workshop aims to bring together researchers from various
fields, including adversarial machine learning, robust vision, and explainable
AI, to discuss recent research and future directions for adversarial robustness
and explainability, with a particular focus on real-world scenarios.
</p>

<p class="lead">
The topics involved in the workshop include but are not limited to:
</p>

    <ul class="lead">

    <li> Robustness of large/foundation vision/language models.</li>

    <li> Discovery of real-world adversarial examples. </li>

    <li> Datasets for evaluating model robustness. </li>

    <li> Novel architectures that are adversarially robust. </li>

    <li> Improving generalization performance of computer vision systems to adversarial or out-of-distribution samples. </li>

    <li> Structured deep models and explainable AI. </li>

    <li> Bias, and fairness in large vision and language models. </li>

    <li> Detection of generated images and texts. </li>

    <li> Data privacy protection in distributed/federated learning. </li>

    <li> Backdoor/poisoning attack and defense. </li>

    </ul>

</div><!-- container-->




<br>
<hr>
<br>
<div class="text-center" id="speakers">
<h1>Speakers</h1>
</div>
<br>


<div class="container text-center">
    <!-- Three columns of text below the carousel -->
    <div class="row">

      <div class="col">
		<a href="https://hazirbas.com/">
        <img class="rounded-circle" width="200" height="auto" src="assets/caner.jpg"><rect width="100%" height="100%"></rect></img>
        <h3 class="fw-normal">Caner Hazirbas</h3>
		</a>
        <p style="color:grey">Meta AI</p>
      </div><!-- /div -->
      <div class="col">
		<a href="http://www.liweiwang-pku.com/">
        <img class="rounded-circle" width="200" height="auto" src="assets/liwei.png"><rect width="100%" height="100%"></rect></img>
        <h3 class="fw-normal">Liwei Wang</h3>
		</a>
        <p style="color:grey">Peking University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://ml.cs.tsinghua.edu.cn/~yinpeng/">
        <img class="rounded-circle" width="200" height="auto" src="assets/YinpengDong.png"><rect width="100%" height="100%"></rect></img>
        <h3 class="fw-normal">Yinpeng Dong</h3>
		</a>
        <p style="color:grey">Tsinghua University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://pages.cs.wisc.edu/~sharonli/">
        <img class="rounded-circle" width="200" height="auto" src="assets/yixuanli.jpeg"><rect width="100%" height="100%"></rect></img>
        <h3 class="fw-normal">Yixuan Li</h3>
		</a>
        <p style="color:grey">University of Wisconsin-Madison</p>
      </div><!-- /div -->
      <div class="col">
        <img class="rounded-circle" width="200" height="auto" src="assets/placeholder.png"><rect width="100%" height="100%"></rect></img>
        <h3 class="fw-normal">TBD</h3>
        <p style="color:grey">TBD</p>
      </div><!-- /div -->
    </div><!-- /.row -->
</div><!-- /.container -->




<br>
<hr>
<br>
<div class="text-center" id="schedule">
<h1>Schedule</h1>
</div>
<br>

<div class="container text-center">
<div class="spinner-border" role="status">
  <span class="visually-hidden">Loading...</span>
</div>

<div class="container text-center">
<table class="table">
  <thead>
    <tr>
      <th scope="col">Date</th>
      <th scope="col">Time</th>
      <th scope="col">Content</th>
      <th scope="col">Speaker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">TBD</th>
      <td>9:00 - 9:30</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>9:30 - 10:00</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>10:00 - 10:30</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>10:30 - 11:00</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>11:00 - 11:30</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>14:30 - 15:00</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>15:00 - 15:30</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>15:30 - 16:00</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>16:00 - 16:30</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
    <tr>
      <th scope="row">TBD</th>
      <td>16:30 - 17:00</td>
      <td>TBD</td>
      <td>TBD</td>
    </tr>
  </tbody>
</table>
</div>

</div><!--container-->





<br>
<hr>
<br>
<div class="text-center" id="organizers">
<h1>Organizing Committee</h1>
</div>
<br>


<div class="container text-center">
    <!-- Three columns of text below the carousel -->
    <div class="row">

      <div class="col">
        <a href="https://scholar.google.com/citations?user=N1-l4GsAAAAJ&hl=en">
        <img class="rounded-circle" width="100" height="auto" src="assets/YutongBai.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Yutong Bai</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://cdluminate.github.io/">
        <img class="rounded-circle" width="100" height="auto" src="assets/mozhou.jpeg"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Mo Zhou</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /div -->
      <div class="col">
        <a href="https://scholar.google.com/citations?user=YR7re-cAAAAJ&hl">
        <img class="rounded-circle" width="100" height="auto" src="assets/AngtianWang.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Angtian Wang</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://vsehwag.github.io/">
        <img class="rounded-circle" width="100" height="auto" src="assets/vikash.jpg"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Vikash Sehwag</h5>
		</a>
        <p style="color:grey">Princeton University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://adamkortylewski.com/">
        <img class="rounded-circle" width="100" height="auto" src="assets/AdamKortylewski.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Adam Kortylewski</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://cihangxie.github.io/">
        <img class="rounded-circle" width="100" height="auto" src="assets/cihangxie.jpeg"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Cihang Xie</h5>
		</a>
        <p style="color:grey">University of California, Santa Cruz</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://yisenwang.github.io/">
        <img class="rounded-circle" width="100" height="auto" src="assets/yisen.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Yisen Wang</h5>
		</a>
        <p style="color:grey">Peking University</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://jungyhuk.github.io/">
        <img class="rounded-circle" width="100" height="auto" src="assets/XinyunChen.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Xinyun Chen</h5>
		</a>
        <p style="color:grey">University of California, Berkeley</p>
      </div><!-- /div -->
      <div class="col">
		<a href="https://www.cc.gatech.edu/~judy/">
        <img class="rounded-circle" width="100" height="auto" src="assets/JudyHoffman.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Judy Hoffman</h5>
		</a>
        <p style="color:grey">Georgia Tech</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="https://people.eecs.berkeley.edu/~dawnsong/">
        <img class="rounded-circle" width="100" height="auto" src="assets/DawnSong.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Dawn Song</h5>
		</a>
        <p style="color:grey">University of California, Berkeley</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="http://ml.cs.tsinghua.edu.cn/~jun/index.shtml">
        <img class="rounded-circle" width="100" height="auto" src="assets/JunZhu.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Jun Zhu</h5>
		</a>
        <p style="color:grey">Tsinghua University</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="https://engineering.jhu.edu/faculty/rama-chellappa/">
        <img class="rounded-circle" width="100" height="auto" src="assets/rama.jpg"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Rama Chellapa</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="https://ganghua.org/">
        <img class="rounded-circle" width="100" height="auto" src="assets/GangHua.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Gang Hua</h5>
		</a>
        <p style="color:grey">Wormpex AI Research</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="https://engineering.jhu.edu/faculty/vishal-patel/">
        <img class="rounded-circle" width="100" height="auto" src="assets/vishal.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Vishal M. Patel</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="http://ml.cs.tsinghua.edu.cn/~yinpeng/">
        <img class="rounded-circle" width="100" height="100" src="assets/YinpengDong.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Yinpeng Dong</h5>
		</a>
        <p style="color:grey">Tsinghua University</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="https://yingwei.li/">
        <img class="rounded-circle" width="100" height="auto" src="assets/YingweiLi.jpg"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Yingwei Li</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="http://xujuefei.com/">
        <img class="rounded-circle" width="100" height="auto" src="assets/felix.jpg"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Felix Juefei-Xu</h5>
		</a>
        <p style="color:grey">Meta AI</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="http://www.cs.jhu.edu/~ayuille/index.html">
        <img class="rounded-circle" width="100" height="auto" src="assets/alan.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Alan L. Yuille</h5>
		</a>
        <p style="color:grey">Johns Hopkins University</p>
      </div><!-- /.div -->
      <div class="col">
		<a href="https://scholar.google.com/citations?user=bvG0PeEAAAAJ&hl=en">
        <img class="rounded-circle" width="100" height="100" src="assets/SiyueWang.png"><rect width="100%" height="100%"></rect></img>
        <h5 class="fw-normal">Siyue Wang</h5>
		</a>
        <p style="color:grey">Microsoft Security Research</p>
      </div><!-- /.div -->
    </div><!-- /.row -->
</div><!-- /.container -->


<br>
<hr>
<br>
<div class="text-center" id="program-committee">
<h1>Program Committee</h1>
</div>
<br>

<div class="container text-center">
<div class="spinner-border" role="status">
  <span class="visually-hidden">Loading...</span>
</div>
</div><!--container-->


<br>
<hr>
<br>
<div class="text-center" id="authorguide">
<h1>Publication Process and Author Guide</h1>
</div>
<br>

<div class="container lead">

<p>
Please follow the <a href="https://iccv2023.thecvf.com/policies-361500-2-20-15.php">ICCV2023 author policies</a>,
as well as the <a href="https://iccv2023.thecvf.com/submission.guidelines-361600-2-20-16.php">ICCV2023 submission guidelines</a>.
It is also suggested to check the <a href="https://iccv2023.thecvf.com/author.faqs-361800-2-20-18.php">ICCV2023 Author FAQs</a>.
We accept two types of submissions, i.e., long papers and extended abstracts.
</p>


<p>
<u>Long papers</u> in the AROW workshop will be published by IEEE/CVF. The following guidelines must be respected:
</p>
<ul>

<li>There will be a transfer of copyright to IEEE/CVF.
The papers will then be available in paid form from IEEE or free of charge on the CVF website.
The papers will not appear in individual proceedings for each workshop, but under the generic title "ICCV23 Workshops".</li>

<li>The list of papers accepted for the workshops must be provided by August 07, 2023 and the authors must submit the final version of their papers by August 21, 2023 on an IEEE platform, if publishing with IEEE; the platform will be informed later before the deadline.</li>

<li>The maximum number of pages for submissions is <u>eight</u> (excluding the references). Overlength papers will be desk-rejected without review. The papers should not exceed 5MB in size and the ICCV template <a href="https://iccv2023.thecvf.com/iccv2023authorkit-38--NQ.php">[iccv2023AuthorKit.zip]</a> is required. An example submission paper with detailed instructions can be found in <a href="https://iccv2023.thecvf.com/latexauthor.guidelines.for.iccv.proceedings-38--MQ.php">this PDF</a>.</li>

<li>Each published paper must have at least one author registered for the workshop under an AUTHOR registration; Virtual Registrations will not cover paper submissions.</li>

<li>The deadline for supplementary material (if applicable) is the same as the paper submission deadline.</li>

<li>All submissions should be anonymized. The reviewing process is double-blind.</li>

</ul>

<p>We also accept <u>extended abstracts</u>. Note, different from the long papers:</p>
<ul>
<li>Papers are limited to <u>four</u> pages excluding references.</li>
<li>Extended abstracts will <b>NOT</b> be included in the official ICCV proceedings.
</ul>

</div>



<br>
<hr>
<br>
<div class="text-center container lead" id="papers">
<h1>Accepted Long Papers</h1>
<p>In total 13 long papers are accepted.</p>
</div>
<br>

<div class="container lead">
<ul>

<!-- 0005 -->
<li><b>Adversarial Examples with Specular Highlights</b>
<p>Vanshika Vats (Indraprastha Institute of Information Technology, Delhi)*; Koteswar Rao Jerripothula (IIIT Delhi)</p>
</li>

<!-- 0006 -->
<li><b>IPCert: Provably Robust Intellectual Property Protection for Machine Learning</b>
<p>Zhengyuan Jiang (Duke university)*; Minghong Fang (The Ohio State University); Neil Zhenqiang Gong (Duke University)</p>
</li>

<!-- 0007 -->
<li><b>Fair Robust Active Learning by Joint Inconsistency</b>
<p>Tsung-Han Wu (National Taiwan University)*; Hung-Ting Su (National Taiwan University); Shang-Tse Chen (National Taiwan University); Winston H. Hsu (National Taiwan University)</p>
</li>

<!-- 0008 -->
<li><b>Classification robustness to common optical aberrations</b>
<p>Patrick M√ºller (University of Siegen)*; Alexander Braun (University of Applied Sciences D√ºsseldorf); Margret Keuper (University of Siegen, Max Planck Institute for Informatics)</p>
</li>

<!-- 0010 -->
<li><b>ThermRad: A Multi-modal Dataset for Robust 3D Object Detection under Challenging Conditions</b>
<p>Qiao Yan (Nanyang Technological University)*; Yihan Wang (Nanyang Technological University)</p>
</li>

<!-- 0011 -->
<li><b>Defense-Prefix for Preventing Typographic Attacks on CLIP</b>
<p>Hiroki Azuma (The University of Tokyo)*; Yusuke Matsui (The University of Tokyo)</p>
</li>

<!-- 0012 -->
<li><b>Efficient Combination of Deep Learning Models for Caption Enrichment</b>
<p>Hidetomo Sakaino (Weathernews Inc.)*; Nguyen X Nam (Bunbu); Bach Hoang Nguyen (Bunbusoft)</p>
</li>

<!-- 0015 -->
<li><b>PRAT: PRofiling Adversarial aTtacks</b>
<p>rahul ambati (University of Central Florida)*; Naveed Akhtar (The University of Western Australia); Yogesh Rawat (University of Central Florida); Ajmal Mian (University of Western Australia)</p>
</li>

<!-- 0019 -->
<li><b>On the Adversarial Robustness of Multi-Modal Foundation Models</b>
<p>Christian Schlarmann (University of T√ºbingen)*; Matthias Hein (University of T√ºbingen)</p>
</li>

<!-- 0022 -->
<li><b>BLACK-BOX ATTACKS ON IMAGE ACTIVITY PREDICTION AND ITS NATURAL LANGUAGE EXPLANATIONS</b>
<p>Alina Elena Baia (Idiap Research Institute)*; Valentina Poggioni (University of Perugia); ANDREA CAVALLARO (Queen Mary University of London, UK)</p>
</li>

<!-- 0023 -->
<li><b>OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks</b>
<p>Ofir Bar Tal (TAU); Adi Haviv (Tel Aviv University)*; Amit H Bermano (Tel-Aviv University)</p>
</li>

<!-- 0032 -->
<li><b>On the unreasonable vulnerability of transformers for image restoration and an easy fix</b>
<p>Shashank Agnihotri (University of Siegen)*; Kanchana Vaishnavi Gandikota (University of Siegen); Julia Grabinski (University of Siegen); Paramanand Chandramouli (University of Siegen); Margret Keuper (University of Siegen, Max Planck Institute for Informatics)</p>
</li>

<!-- 0033 -->
<li><b>Targeted Adversarial Attacks on Generalizable Neural Radiance Fields</b>
<p>Andras Horvath (Peter Pazmany Catholic University)*; Csaba Jozsa (Nokia Bell Labs)</p>
</li>

</ul>
</div>

<br>
<br>
<div class="text-center container lead">
<h1>Accepted Extended Abstracts</h1>
<p>In total 6 extended abstracts are accepted.</p>
</div>

<div class="container lead"> <ul>

<!-- 0009 -->
<li><b>FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks</b>
<p>Hunmin Yang (KAIST)*; Jongoh Jeong (KAIST); Kuk-Jin Yoon (KAIST)</p>
</li>

<!-- 0014 -->
<li><b>Generalizability of Adversarial Robustness Under Distribution Shifts</b>
<p>Kumail Alhamoud (KAUST)*; Hasan Abed Al Kader Hammoud (King Abdullah University of Science and Technology ); Motasem Alfarra (KAUST); Bernard Ghanem (KAUST)</p>
</li>

<!-- 0020 -->
<li><b>Towards the Adversarial Robustness of Vision-Language Model with Chain-of-Thought Reasoning</b>
<p>Zefeng Wang (TUM); Zhen Han (LMU Munich); Jindong Gu (University of Oxford)*; Shuo Chen (LMU Munich); Volker Tresp (LMU)</p>
</li>

<!-- 0025 -->
<li><b>Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable Example Attacks</b>
<p>Tianrui Qin (SIAT); Xitong Gao (Shenzhen Institutes of Advanced Technology,Chinese Academy of Sciences)*; juanjuan zhao (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences); Kejiang Ye (Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences); Cheng-Zhong Xu (University of Macau)</p>
</li>

<!-- 0031 -->
<li><b>Adversarial Bayesian Augmentation for Single-Source Domain Generalization</b>
<p>Sheng Cheng (Arizona State University)*; Tejas Gokhale (Arizona State University); Yezhou Yang (Arizona State University)<p>
</li>

<!-- 0034 -->
<li><b>Weakly-supervised detection of diffusion-based image manipulations</b>
<p>Elisabeta Oneata (Bitdefender)*; Dan Oneata (Politehnica University of Bucharest); Dragos Tantaru (Bitdefender)</p>
</li>

</ul> </div>



<br>
<hr>
<br>
<div class="text-center" id="sponsor">
<h1>Sponsor</h1>
</div>
<br>

<div class="container text-center">
<h4>Please <a href="#contact">contact us</a> (see bottom of this page) if you are interested in sponsoring this workshop!</h4>

</div><!--container-->


<br>
<hr>
<br>
<div class="text-center" id="related">
<h1>Related Workshops</h1>
</div>
<br>


<div class="container">

<ul>
	<li><a href="https://eccv22-arow.github.io/">Adversarial Robustness In the Real World (Workshop at ECCV 2022; the 3rd AROW Workshop)</a></li>
	<li><a href="https://iccv21-adv-workshop.github.io/">Adversarial Robustness In the Real World (Workshop at ICCV 2021; 2nd AROW Workshop)</a></li>
	<li><a href="https://eccv20-adv-workshop.github.io/">Adversarial Robustness In the Real World (Workshop at ECCV 2020; 1st AROW Workshop)</a></li>

	<li><a href="https://adv-workshop-2020.github.io/">Adversarial Machine Learning in Computer Vision (CVPR 2020)</a></li>

	<li><a href="http://www.robustvision.net/">Robust Vision Challenge 2020</a></li>

	<li><a href="https://aisecure-workshop.github.io/amlcvpr2021/">
			Workshop on Adversarial Machine Learning in Real-World Computer Vision Systems and Online Challenges (CVPR 2021)</a></li>

	<li><a href="https://advml-workshop.github.io/icml2021/">
			Adversarial Machine Learning (ICML 2021)</a></li>

	<li><a href="https://icml.cc/virtual/2022/workshop/13458">
			ICML workshop on Machine Learning for Cybersecurity (ICML-ML4Cyber) (ICML 2022)</a></li>

	<li><a href="https://icml.cc/virtual/2022/workshop/13455">
			New Frontiers in Adversarial Machine Learning (ICML 2022)</a></li>

	<li><a href="https://nips.cc/virtual/2022/workshop/49959">
			Trustworthy and Socially Responsible Machine Learning (NeurIPS 2022)</a></li>

	<li><a href="https://nips.cc/virtual/2022/workshop/49986">
			Workshop on Machine Learning Safety (NeurIPS 2022)</a></li>

	<li><a href="https://nips.cc/virtual/2022/workshop/49972">
			Progress and Challenges in Building Trustworthy Embodied AI (NeurIPS 2022)</a></li>

	<li><a href="https://artofrobust.github.io/">
			The Art of Robustness: Devil and Angel in Adversarial Machine Learning (CVPR 2022)</a></li>
</ul>

<p class='lead'>Here are some reference links:</p>

<ul>
<li><a href="https://iccv2023.thecvf.com/list.of.accepted.workshops-90.php">ICCV 2023 list of accepted workshops</a></li>
</ul>
</div><!--container-->

<br>
<hr>
<br>
<div class="text-center" id="tweets">
<h1>Social Network Updates</h1>
</div>
<br>

<div class='container text-center'>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üì¢ [Deadline Extension] Good news! We have extended the submission deadline for the 4th Workshop on Adversarial Robustness In the Real World, ICCV2023!<br><br>üìÖ New DDL: July 20, 2023, 23:59 PT<br><br>üì∑ Workshop Website: <a href="https://t.co/r9tu5UvuG8">https://t.co/r9tu5UvuG8</a><a href="https://twitter.com/hashtag/AROW?src=hash&amp;ref_src=twsrc%5Etfw">#AROW</a> <a href="https://twitter.com/hashtag/ICCV2023?src=hash&amp;ref_src=twsrc%5Etfw">#ICCV2023</a> <a href="https://twitter.com/hashtag/AdversarialRobustness?src=hash&amp;ref_src=twsrc%5Etfw">#AdversarialRobustness</a></p>&mdash; M. Zhou (@MZhou73277685) <a href="https://twitter.com/MZhou73277685/status/1681201839092695040?ref_src=twsrc%5Etfw">July 18, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üì¢ [Call For Papers] We invite participants to submit their work to the 4th Workshop on Adversarial Robustness In the Real World, ICCV 2023, France!<br><br>üì∑ Workshop Website: <a href="https://t.co/r9tu5UvuG8">https://t.co/r9tu5UvuG8</a><a href="https://twitter.com/hashtag/AROW?src=hash&amp;ref_src=twsrc%5Etfw">#AROW</a> <a href="https://twitter.com/hashtag/ICCV2023?src=hash&amp;ref_src=twsrc%5Etfw">#ICCV2023</a> <a href="https://twitter.com/hashtag/AdversarialRobustness?src=hash&amp;ref_src=twsrc%5Etfw">#AdversarialRobustness</a> <a href="https://twitter.com/hashtag/DeepLearning?src=hash&amp;ref_src=twsrc%5Etfw">#DeepLearning</a> <a href="https://twitter.com/hashtag/ComputerVision?src=hash&amp;ref_src=twsrc%5Etfw">#ComputerVision</a> <a href="https://twitter.com/hashtag/Paris?src=hash&amp;ref_src=twsrc%5Etfw">#Paris</a></p>&mdash; M. Zhou (@MZhou73277685) <a href="https://twitter.com/MZhou73277685/status/1675380995456126976?ref_src=twsrc%5Etfw">July 2, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üì¢ Exciting news! Join us at the 4th Workshop on Adversarial Robustness In the Real World, happening at ICCV 2023 in Paris, France. üåçü§ñ<br><br>üîó Workshop Website: <a href="https://t.co/ELnVUJyg3H">https://t.co/ELnVUJyg3H</a><a href="https://twitter.com/hashtag/AROW?src=hash&amp;ref_src=twsrc%5Etfw">#AROW</a> <a href="https://twitter.com/hashtag/ICCV2023?src=hash&amp;ref_src=twsrc%5Etfw">#ICCV2023</a> <a href="https://twitter.com/hashtag/AdversarialRobustness?src=hash&amp;ref_src=twsrc%5Etfw">#AdversarialRobustness</a> <a href="https://twitter.com/hashtag/DeepLearning?src=hash&amp;ref_src=twsrc%5Etfw">#DeepLearning</a> <a href="https://twitter.com/hashtag/ComputerVision?src=hash&amp;ref_src=twsrc%5Etfw">#ComputerVision</a> <a href="https://twitter.com/hashtag/Paris?src=hash&amp;ref_src=twsrc%5Etfw">#Paris</a></p>&mdash; M. Zhou (@MZhou73277685) <a href="https://twitter.com/MZhou73277685/status/1675377802349264896?ref_src=twsrc%5Etfw">July 2, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>


<br>

<footer class="py-5 text-center text-body-secondary bg-body-tertiary" id="contact">
  <p>Please contact <a href="mailto:ytongbai@gmail.com">Yutong Bai</a> or <a href="mailto:mzhou32@jhu.edu">Mo Zhou</a> if you have questions. Issues about the website can be posed at <a href="https://github.com/iccv23-arow/iccv23-arow.github.io/issues">Github issues</a>. </p>
  <p>The webpage is written by Mo Zhou from scratch with inspirations from the previous AROW workshop websites. The <a href="https://github.com/iccv23-arow/iccv23-arow.github.io">HTML source code</a> is released under the CC-0 license.</p>
  <p>ICCV 2023 AROW Workshop</p>
  <p class="mb-0">
    <a href="#">Back to top</a>
  </p>
</footer>

  </body>
</html>

